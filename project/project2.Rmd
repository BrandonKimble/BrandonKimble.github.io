---
title: 'Project 2: Modeling, Testing, and Predicting'
author: "Brandon Kimble BMK882"
date: ''
output:
  html_document:
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: yes
---

```{r setup, include=FALSE}
library(knitr)
hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
  # this hook is used only when the linewidth option is not NULL
  if (!is.null(n <- options$linewidth)) {
    x = knitr:::split_lines(x)
    # any lines wider than n should be wrapped
    if (any(nchar(x) > n)) x = strwrap(x, width = n)
    x = paste(x, collapse = '\n')
  }
  hook_output(x, options)
})

knitr::opts_chunk$set(echo = TRUE, eval = TRUE,fig.align="center",warning=FALSE,message=FALSE,fig.width=8, fig.height=5, linewidth=60)
options(tibble.width = 100,width = 100)
library(tidyverse)
```

```{r}
library(tidyverse)
library(dplyr)
library(ggplot2)
library(ggExtra)
library(lmtest)
library(sandwich)
library(plotROC)
library(glmnet)

corruption_index = read.csv('merged_cpi_data.csv')
crypto_volume = read.csv('Book2.csv')
```
    
```{r}
volume = crypto_volume %>% 
    mutate("WE/EU"= (WE.EU + WE.EU.1) / 2, .keep="unused") %>%
    mutate("AP"= (AP + AP.1) / 2, .keep="unused") %>%
    mutate("AME"= (AME + AME.1) / 2, .keep="unused") %>%
    mutate(date = as.Date(date, format="%m/%d/%y")) %>%
    mutate(Year = format(date, format="%Y")) %>%
    mutate_all(as.numeric) %>% na.omit() %>%
    pivot_longer(cols=2:7, names_to="Region", values_to="Volume") %>%
    group_by(Year, Region) %>% summarize(Volume = mean(Volume))
    
data = corruption_index %>%
    select(Year, Country, CPI=CPI.Score, Region) %>%
    filter(Year>=2013 & Year<=2018) %>% na.omit() %>%
    left_join(volume, by=c("Year", "Region"))
```

Cryptocurrency is regarded by some to be the catalyst that sends the world into the next digital revolution, much like the internet did in the late 90s. Cryptocurrency is digital currency that is attached to no single governing body or physical store of value. If widely adopted, such a currency could represent the most democratizing technology created thus far in history. Given that anyone in the world now has the option to invest in digital currencies, it is very possible that populations unhappy with their government due to corruption might turn to cryptocurrencies as a hedge against a corrupt system. I expect trading volume to increase in a region if the region's corruption perception index increases. That is if people feel as though their government is corrupt, they will turn to unregulated forms of currency. 

To find out if this trend has already started, I gathered data from the Transparency International’s Corruption Perception Index, which is currently the most robust measure of the corruption available to the public. I then downloaded trade volume data from the largest peer-to-peer cryptocurrency exchange, LocalBitcoin. The tidyied dataset contains cryptocurrency trade volume in US dollars (e.g., $10M) averaged per year, and the Corruption Perception Index (CPI) for each year, along with the associated country and region. The time scale range from 2013 to 2018 and the regional abbreviations are as follows: AME - Americas, SSA - Sub-Saharan Africa, ECA - Eastern Europe & Central Asia, MENA - Middle East And North Africa, WE/EU - Western Europe & European Union, and AP - Asia Pacific. The full dataset contains 1056 observations.

```{r}
man1 = manova(cbind(CPI, Volume)~Region, data=data)
summary(man1)
summary.aov(man1)
pairwise.t.test(data$CPI, data$Region, p.adj="none")
pairwise.t.test(data$Volume, data$Region, p.adj="none")
```

The MANOVA suggest significant differences were found among the five regions for at least one of the dependent variables, *Pillai trace* = 0.53, *pseudo F*(10, 2100) = 75.18, *p* < 0.0001. The univariate ANOVAs for each dependent variable were conducted, using the Bonferroni method for controlling Type I error rates for multiple comparisons. The univariate ANOVAs for CPI and Volume were also significant, *F*(5, 1050) = 120.24, *p* < 0.0001, and *F*(5, 1050) = 40.93, *p* < 0.0001, respectively. The follow up post-hoc t-tests suggest many regions have mean differences in CPI and Volume. However, since there have been 33 tests done, the alpha cut-off sits at .05/33 which is roughly 0.0015. Using this cut-off to adjust for multiple comparisons, multiple regions are still significantly different from each other in terms of CPI and Volume (bonferroni α = .05/33 = 0.0015). As for meeting MANOVA assumptions, given that the majority of the world has a long way to go in terms of development and access to cryptocurrency trading platforms, this data likely violates the assumption of multivariate normality. There are far fewer regions with high CPI scores and cryptocurrency volume. For these reasons it is very likely we violate other MANOVA assumptions.

```{r} 
#compute distances/dissimilarities
dists = data %>% select(CPI, Volume) %>% dist()

#compute observed F
SST = sum(dists^2)/1056
SSW = data %>% group_by(Region) %>% select(Region, CPI, Volume) %>%
  do(d=dist(.[-1],"euclidean")) %>% ungroup() %>%
  summarize(sum(d[[1]]^2)/186 + sum(d[[2]]^2)/174 + sum(d[[3]]^2)/114 + sum(d[[4]]^2)/108 + sum(d[[5]]^2)/288 + sum(d[[6]]^2)/186) %>% pull

F_obs = ((SST-SSW)/(5))/(SSW/(1050)) #observed F statistic
F_obs

# compute null distribution for F
Fs = replicate(1000,{
  new = data %>% mutate(Region=sample(Region)) #permute the species vector
  SSW = new %>% group_by(Region) %>% select(Region, CPI, Volume) %>%
    do(d=dist(.[-1],"euclidean")) %>% ungroup() %>%
    summarize(sum(d[[1]]^2)/186 + sum(d[[2]]^2)/174 + sum(d[[3]]^2)/114 + sum(d[[4]]^2)/108 + sum(d[[5]]^2)/288 + sum(d[[6]]^2)/186) %>% pull
  
  ((SST-SSW)/5)/(SSW/1050) #calculate new F ratio on randomized data
})

{hist(Fs, prob = T); abline(v=F_obs, col="red", add=T)}
mean(Fs>F_obs)
```

Randomization-test MANOVA (PERMANOVA)

Null Hypothesis: For both response variables (CPI, Volume), means for each region are equal.
Alternative Hypothesis: For at least one response variable, at least one region's mean is different.

Since the p-value is effectively zero, we reject the null hypothesis as we did before, but this time we haven't made any assumptions. None of the 1000 F statistics generated under the null hypothesis were larger than our actual F statistic (40.93). This affirms that regions do differ from each other based on CPI and volume (*p* < 0.0001).
    
```{r}
data$CPI_c = data$CPI - mean(data$CPI, na.rm = T)
fit = lm(Volume ~ Region * CPI_c, data = data)
summary(fit)

ggplot(data, aes(CPI, Volume, color = Region)) + geom_smooth(method = "lm", se = F, fullrange = T) +
  geom_point() + geom_vline(xintercept=0, lty=2) + geom_vline(aes(xintercept=mean(CPI)))

resids = fit$residuals
fitvals = fit$fitted.values
ggplot() + geom_point(aes(fitvals,resids)) + geom_hline(yintercept=0, color='red')
bptest(fit)

ggplot() + geom_histogram(aes(resids), bins=20)
ggplot() + geom_qq(aes(sample=resids)) + geom_qq_line(aes(sample=resids))
ks.test(resids, "pnorm", mean=0, sd(resids))

coeftest(fit, vcov=vcovHC(fit))
```

In interpreting the coefficient estimates, the intercept value of 47388816 represents the predicted trade volume in AME (Americas) at an average CPI (Corruption Perception Index). Hypothetically, lets say every region has an average CPI score. While controlling for CPI, AP (Asia Pacific) would have a predicted trade volume that is \$16671560 lower on average than that of AME, ECA (Eastern Europe & Central Asia) would have a predicted trade volume that is \$24627758 greater, MENA (Middle East & North Africa) would have a predicted volume that is \$43202143 lower, SSA (Sub-Saharan Africa) would have a predicted volume that is \$25483826 lower, and WE/EU (Western Europe & European Union) would have a predicted volume that is \$19584845 lower. Controlling for region, for every one-unit increase in AME's CPI, predicted trade volume decreases by \$23980. Slope of CPI on volume for AP is 74553 greater than for AME; ECA's is 619913 greater; MENA's is 18478 greater; SSA's is 19567 greater, and WE/EU's is 32982 greater.
  
According to the adjusted R-squared value, roughly 15.6% of variability in trade volume is explained by the model.
  
Using homoskedasticity robust standard errors, all regions retained their significant effects while controlling for CPI. However, since the standard errors decreased for all regions but ECA, ECA decreased in significance (*t* = 2.1464, *df* = 1044, *p* < 0.01), while WE/EW increased in significance (*t* = -4.6569, *df* = 1044, *p* < 0.0001). The remaining regions, AP (*t* = -4.3580, *df* = 1044, *p* < 0.0001), MENA (*t* = -15.2503, *df* = 1044, *p* < 0.0001), and SSA (*t* = -7.1761, *df* = 1044, *p* < 0.0001) stayed fairly consistent in terms of their significance. The coefficient estimates for CPI controlling for region and all interactions remained insignificant despite the use of robust standard errors.
  
```{r}
samp = replicate(5000, {
  boot_dat = sample_frac(data, replace=T)
  fit = lm(Volume ~ Region * CPI_c, data = boot_dat)
  coef(fit)
})
samp %>% t %>% as.data.frame %>% summarize_all(sd)
```

When rerunning the same regression model while computing bootstrapped standard errors (SEs), the model produced SEs that were larger than both the original SEs and the robust SEs, with the exception of the SEs of MENA, SSA, and WE/EU, which are now 2918839, 3764402, and 4536599, respectively. These three regions were given larger SEs before computing robust SEs. The original SEs were as follows: 4703968, 4090960, and 5888452, respectively. However, these SE values are larger than the robust SEs.
    
```{r}
class_diag <- function(probs,truth){
  #CONFUSION MATRIX: CALCULATE ACCURACY, TPR, TNR, PPV
  
  if(is.character(truth)==TRUE) truth<-as.factor(truth)
  if(is.numeric(truth)==FALSE & is.logical(truth)==FALSE) truth<-as.numeric(truth)-1
  
  tab<-table(factor(probs>.5,levels=c("FALSE","TRUE")), factor(truth, levels=c(0,1)))
  acc=sum(diag(tab))/sum(tab)
  sens=tab[2,2]/colSums(tab)[2]
  spec=tab[1,1]/colSums(tab)[1]
  ppv=tab[2,2]/rowSums(tab)[2]
  
  #CALCULATE EXACT AUC
  ord<-order(probs, decreasing=TRUE)
  probs <- probs[ord]; truth <- truth[ord]
  
  TPR=cumsum(truth)/max(1,sum(truth)) 
  FPR=cumsum(!truth)/max(1,sum(!truth))
  
  dup <-c(probs[-1]>=probs[-length(probs)], FALSE)
  TPR <-c(0, TPR[!dup], 1); FPR<-c(0, FPR[!dup], 1)
  n <- length(TPR)
  auc <- sum(((TPR[-1] + TPR[-n])/2) * (FPR[-1] - FPR[-n]))

  data.frame(acc,sens,spec,ppv,auc)
}

data = data %>% mutate(Region=ifelse(Region=="SSA", "Sub-Saharan Africa", "elsewhere"))
data = data %>% mutate(y=ifelse(Region=="Sub-Saharan Africa", 1, 0))

fit = glm(y~Volume + CPI, data=data, family="binomial")
data$probs = predict(fit, type="response")
data$Region = factor(data$Region, levels=c("Sub-Saharan Africa", "elsewhere"))

# coefficients
coeftest(fit)

# confusion matrix
table(predict=as.numeric(data$probs>.5), truth=data$y) %>% addmargins

# classification diagnostics
class_diag(data$probs, data$y)

# density plot
data$logit = predict(fit, type="link")

data %>% ggplot() + geom_density(aes(logit, color=Region, fill=Region), alpha=.4) +
  theme(legend.position=c(.85,.85)) + geom_vline(xintercept=0) + xlab("logit (log-odds)") +
  geom_rug(aes(logit, color=Region))

ROCplot<-ggplot(data) + geom_roc(aes(d=Region, m=probs), n.cuts=0) 

ROCplot
calc_auc(ROCplot)

```

The intercept coefficient estimate in this case represents the odds of a region being SSA when volume and CPI are zero. Controlling for CPI, going up one-unit in volume multiplies odds of a region being SSA by a factor of $e^{-9.4928e-09} = 7.67e-16$ (*p* < 0.0001). Controlling for volume, going up one-unit in CPI multiplies odds of a region being SSA by a factor of $e^{-5.1765e-02} = 1.05e-7$ (*p* < 0.0001). 

Overall, Accuracy is the proportion of correctly identified regions (0.723). Sensitivity (True Positive Rate, TPR) is the proportion of SSA regions correctly identified (0.184). Specificity (True Negative Rate, TNR) is the proportion of non-SSA regions correctly identified (0.926). Precision (Positive Predictive Value, PPV) is the proportion regions identified as SSA that actually are (0.482). Area under the curve (AUC) quantifies how well we are predicting overall. In our case the AUC represents the probability that a randomly selected region that is SSA has a higher predicted probability than a randomly selected region that is not SSA. According to AUC, the model overall prediction performance is fair (0.742). The ROC curve suggest it is slightly difficult to predict SSA from just volume and CPI.
    
```{r}
corruption_index = read.csv('/Users/brandonkimble/UNI/Spring_2021/SDS_348/merged_cpi_data.csv')
crypto_volume = read.csv('/Users/brandonkimble/UNI/Spring_2021/SDS_348/Book2.csv')

volume = crypto_volume %>% 
    mutate("WE/EU"= (WE.EU + WE.EU.1) / 2, .keep="unused") %>%
    mutate("AP"= (AP + AP.1) / 2, .keep="unused") %>%
    mutate("AME"= (AME + AME.1) / 2, .keep="unused") %>%
    mutate(date = as.Date(date, format="%m/%d/%y")) %>%
    mutate(Year = format(date, format="%Y")) %>%
    mutate_all(as.numeric) %>% na.omit() %>%
    pivot_longer(cols=2:7, names_to="Region", values_to="Volume") %>%
    group_by(Year, Region) %>% summarize(Volume = mean(Volume))
    
data = corruption_index %>%
    select(Year, Country, CPI=CPI.Score, Region) %>%
    filter(Year>=2013 & Year<=2018) %>% na.omit() %>%
    left_join(volume, by=c("Year", "Region"))

df = data %>% group_by(Country) %>% summarize(count = n())
bool = c(df[,2]==6)
countries = as.vector(df$Country)[bool]
data = data[data$Country %in% countries,]


# in-sample classification diagnostics
data = data %>% mutate(y=ifelse(Region=="SSA", 1, 0))
data$Country = factor(data$Country)
data$Region = NULL

fit = glm(y~Country + Year + CPI + Volume, data=data, family="binomial")
probs = predict(fit, type="response")
class_diag(probs, data$y)


# 10-Fold CV
set.seed(1234)
k = 10
data1 = data[sample(nrow(data)),]
folds = cut(seq(1:nrow(data)), breaks=k, labels=F)
diags = NULL
for (i in 1:k) {      
  train = data1[folds!=i,]
  test = data1[folds==i,]
  truth = test$y
  
  fit = glm(y~Country + Year + CPI + Volume, data=train, family="binomial")
  probs = predict(fit, newdata=test, type="response")
  diags = rbind(diags, class_diag(probs, truth))
}
summarize_all(diags, mean) 


# LASSO
y = as.matrix(data$y)
x = model.matrix(y~-1+.,data=data)[,-1]
x = scale(x)
cv = cv.glmnet(x,y)

{plot(cv$glmnet.fit, "lambda", label=TRUE); abline(v = log(cv$lambda.1se)); abline(v = log(cv$lambda.min),lty=2)}

cv = cv.glmnet(x,y,family="binomial")
lasso = glmnet(x,y,family="binomial",lambda=cv$lambda.1se)
coef(lasso)


# cross-validating LASSO model
k=10
lasso <- data %>% 
  mutate(Angola= ifelse(Country=="Angola", 1, 0)) %>%
  mutate(Benin = ifelse(Country=="Benin", 1, 0)) %>%
  mutate(Botswana= ifelse(Country=="Botswana", 1, 0)) %>%
  mutate(BurkinaFaso= ifelse(Country=="Burkina Faso", 1, 0)) %>%
  mutate(Burundi= ifelse(Country=="Burundi", 1, 0)) %>%
  mutate(CaboVerde= ifelse(Country=="Cabo Verde", 1, 0)) %>%
  mutate(Cameroon= ifelse(Country=="Cameroon", 1, 0)) %>%
  mutate(CentralAfricanRepublic= ifelse(Country=="Central African Republic", 1, 0)) %>%
  mutate(Chad= ifelse(Country=="Chad", 1, 0)) %>%
  mutate(Comoros= ifelse(Country=="Comoros", 1, 0)) %>%
  mutate(CôtedIvoire= ifelse(Country=="Côte d'Ivoire", 1, 0)) %>%
  mutate(DemocraticRepublicoftheCongo= ifelse(Country=="Democratic Republic of the Congo", 1, 0)) %>%
  mutate(Djibouti= ifelse(Country=="Djibouti", 1, 0)) %>%
  mutate(Eritrea= ifelse(Country=="Eritrea", 1, 0)) %>%
  mutate(Ethiopia= ifelse(Country=="Ethiopia", 1, 0)) %>%
  mutate(Gabon= ifelse(Country=="Gabon", 1, 0)) %>%
  mutate(Gambia= ifelse(Country=="Gambia", 1, 0)) %>%
  mutate(Ghana= ifelse(Country=="Ghana", 1, 0)) %>%
  mutate(Guinea= ifelse(Country=="Guinea", 1, 0)) %>%
  mutate(GuineaBissau= ifelse(Country=="Guinea-Bissau", 1, 0)) %>%
  mutate(Kenya= ifelse(Country=="Kenya", 1, 0)) %>%
  mutate(Lesotho= ifelse(Country=="Lesotho", 1, 0)) %>%
  mutate(Liberia= ifelse(Country=="Liberia", 1, 0)) %>%
  mutate(Madagascar= ifelse(Country=="Madagascar", 1, 0)) %>%
  mutate(Malawi= ifelse(Country=="Malawi", 1, 0)) %>%
  mutate(Mali= ifelse(Country=="Mali", 1, 0)) %>%
  mutate(Mauritania= ifelse(Country=="Mauritania", 1, 0)) %>%
  mutate(Mozambique= ifelse(Country=="Mozambique", 1, 0)) %>%
  mutate(Namibia= ifelse(Country=="Namibia", 1, 0)) %>%
  mutate(Niger= ifelse(Country=="Niger", 1, 0)) %>%
  mutate(Nigeria= ifelse(Country=="Nigeria", 1, 0)) %>%
  mutate(Rwanda= ifelse(Country=="Rwanda", 1, 0)) %>%
  mutate(SaoTomePrincipe= ifelse(Country=="Sao Tome & Principe", 1, 0)) %>%
  mutate(Senegal= ifelse(Country=="Senegal", 1, 0)) %>%
  mutate(SierraLeone= ifelse(Country=="Sierra Leone", 1, 0)) %>%
  mutate(Somalia= ifelse(Country=="Somalia", 1, 0)) %>%
  mutate(SouthAfrica= ifelse(Country=="South Africa", 1, 0)) %>%
  mutate(Sudan= ifelse(Country=="Sudan", 1, 0)) %>%
  mutate(Tanzania= ifelse(Country=="Tanzania", 1, 0)) %>%
  mutate(Togo= ifelse(Country=="Togo", 1, 0)) %>%
  mutate(Uganda= ifelse(Country=="Uganda", 1, 0)) %>%
  mutate(Zambia= ifelse(Country=="Zambia", 1, 0)) %>%
  mutate(Zimbabwe= ifelse(Country=="Zimbabwe", 1, 0)) %>%
  dplyr::select(Angola,Benin,Botswana,BurkinaFaso,Burundi,Cameroon,CaboVerde,CentralAfricanRepublic,Chad,Comoros,CôtedIvoire,DemocraticRepublicoftheCongo,Djibouti,Eritrea,Ethiopia,Gabon,Gambia,Ghana,Guinea,GuineaBissau,Kenya,Lesotho,Liberia,Madagascar,Malawi,Mali,Mauritania,Mozambique,Namibia,Niger,Nigeria,Rwanda,SaoTomePrincipe,Senegal,SierraLeone,Somalia,SouthAfrica,Sudan,Tanzania,Togo,Uganda,Zambia,Zimbabwe,Year,CPI,Volume,y)

data1 = lasso[sample(nrow(lasso)),]
folds = cut(seq(1:nrow(lasso)),breaks=k,labels=F)

diags<-NULL
for(i in 1:k){      
  train = data1[folds!=i,]
  test = data1[folds==i,]
  truth = test$y
  
  fit = glm(y~Angola+Benin+Botswana+BurkinaFaso+Burundi+CaboVerde+Cameroon+CentralAfricanRepublic+Chad+Comoros+CôtedIvoire+DemocraticRepublicoftheCongo+Djibouti+Eritrea+Ethiopia+Gabon+Gambia+Ghana+Guinea+GuineaBissau+Kenya+Lesotho+Liberia+Madagascar+Malawi+Mali+Mauritania+Mozambique+Namibia+Niger+Nigeria+Rwanda+SaoTomePrincipe+Senegal+SierraLeone+Somalia+Somalia+SouthAfrica+Sudan+Tanzania+Togo+Uganda+Zambia+Zimbabwe+Year+CPI+Volume, data=train, family="binomial")
  probs = predict(fit, newdata=test, type = "response")
  
  diags = rbind(diags, class_diag(probs, truth))
}
summarize_all(diags, mean)
```

In computing in-sample classification diagnostics, Accuracy, Sensitivity, Specificity, Precision, and AUC were all equal to 1. This would suggest the logistic regression model performed perfectly when using all the variables in the dataset. For the 10-fold CV, the same is true. All metrics were equal 1 for both in-sample and the average out-of-sample classification diagnostics. When given access to the country data, it seems the model is predicting regions perfectly, even under cross-validation. After running the LASSO, it became apparent why the models were performing so well. The variables retained by LASSO accounted for every country belonging to SSA in the dataset. Variable CPI and Volume were also retained, but it seems the country data is what allows the models to perform perfectly. In performing the 10-fold CV using only lasso-selected variables, the model was slightly penalized, which resulted in a out-of-sample AUC that was lower than the initial logistic regressions (0.985). LASSO's regularization of variables due to the complexity of the model likely caused the AUC to decrease. Nevertheless, the overall prediction performance is great.